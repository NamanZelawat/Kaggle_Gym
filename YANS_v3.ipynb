{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "414fe51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "train = load_dataset(\"naver-clova-ix/cord-v2\", split=\"train\")\n",
    "test = load_dataset(\"naver-clova-ix/cord-v2\", split=\"test\")\n",
    "validation = load_dataset(\"naver-clova-ix/cord-v2\", split=\"validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237026f7",
   "metadata": {},
   "source": [
    "### Find out all the labels in the CORD v2 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f638acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({'menu.nm': 2100,\n",
       "          'menu.price': 2093,\n",
       "          'menu.cnt': 1903,\n",
       "          'total.total_price': 784,\n",
       "          'menu.unitprice': 621,\n",
       "          'sub_total.subtotal_price': 541,\n",
       "          'total.cashprice': 526,\n",
       "          'total.changeprice': 502,\n",
       "          'sub_total.tax_price': 362,\n",
       "          'menu.sub.nm': 319,\n",
       "          'total.menuqty_cnt': 233,\n",
       "          'menu.sub.cnt': 142,\n",
       "          'total.creditcardprice': 124,\n",
       "          'menu.sub.price': 123,\n",
       "          'sub_total.etc': 112,\n",
       "          'sub_total.service_price': 98,\n",
       "          'menu.discountprice': 97,\n",
       "          'menu.num': 94,\n",
       "          'sub_total.discount_price': 68,\n",
       "          'total.emoneyprice': 47,\n",
       "          'total.menutype_cnt': 43,\n",
       "          'total.total_etc': 28,\n",
       "          'menu.sub.unitprice': 14,\n",
       "          'menu.etc': 6,\n",
       "          'sub_total.othersvc_price': 2,\n",
       "          'menu.vatyn': 2,\n",
       "          'void_menu.nm': 1,\n",
       "          'void_menu.price': 1,\n",
       "          'menu.itemsubtotal': 1}),\n",
       " 29)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "all_labels = []\n",
    "\n",
    "for sample in train[\"ground_truth\"]:\n",
    "    sample_info = json.loads(sample)[\"valid_line\"]\n",
    "    for val in sample_info:\n",
    "        all_labels.append(val[\"category\"])\n",
    "\n",
    "label_dict = Counter(all_labels)\n",
    "label_dict, len(label_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab09c2f7",
   "metadata": {},
   "source": [
    "### Some labels are very less so replacing them with the neutral label 'O'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76624283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'sub_total.service_price': 'O',\n",
       "  'total.menutype_cnt': 'O',\n",
       "  'sub_total.discount_price': 'O',\n",
       "  'total.total_etc': 'O',\n",
       "  'menu.num': 'O',\n",
       "  'menu.discountprice': 'O',\n",
       "  'total.emoneyprice': 'O',\n",
       "  'menu.sub.unitprice': 'O',\n",
       "  'void_menu.nm': 'O',\n",
       "  'void_menu.price': 'O',\n",
       "  'sub_total.othersvc_price': 'O',\n",
       "  'menu.vatyn': 'O',\n",
       "  'menu.itemsubtotal': 'O',\n",
       "  'menu.etc': 'O'},\n",
       " 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replacing_labels = {}\n",
    "\n",
    "for key, val in label_dict.items():\n",
    "    if val < 100:\n",
    "        replacing_labels[key] = 'O'\n",
    "\n",
    "replacing_labels, len(replacing_labels.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baa2839e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train[1][\"ground_truth\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae8bf337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the categories\n",
    "def map_labels(sample):\n",
    "    sample_info = json.loads(sample[\"ground_truth\"])[\"valid_line\"]\n",
    "    for idx_info, val in enumerate(sample_info):\n",
    "        if val[\"category\"] in replacing_labels:\n",
    "            sample_info[idx_info][\"category\"] = 'O'\n",
    "    \n",
    "    updated_valid_line = {\"valid_line\" : sample_info}\n",
    "    sample[\"ground_truth\"] = json.dumps(updated_valid_line)\n",
    "    return sample\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "074e635f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.map(map_labels)\n",
    "validation = validation.map(map_labels)\n",
    "test = test.map(map_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fff3f826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({'menu.nm': 2100,\n",
       "          'menu.price': 2093,\n",
       "          'menu.cnt': 1903,\n",
       "          'total.total_price': 784,\n",
       "          'menu.unitprice': 621,\n",
       "          'sub_total.subtotal_price': 541,\n",
       "          'total.cashprice': 526,\n",
       "          'O': 502,\n",
       "          'total.changeprice': 502,\n",
       "          'sub_total.tax_price': 362,\n",
       "          'menu.sub.nm': 319,\n",
       "          'total.menuqty_cnt': 233,\n",
       "          'menu.sub.cnt': 142,\n",
       "          'total.creditcardprice': 124,\n",
       "          'menu.sub.price': 123,\n",
       "          'sub_total.etc': 112}),\n",
       " 16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels = []\n",
    "\n",
    "for sample in train[\"ground_truth\"]:\n",
    "    sample_info = json.loads(sample)[\"valid_line\"]\n",
    "    for val in sample_info:\n",
    "        all_labels.append(val[\"category\"])\n",
    "\n",
    "label_dict = Counter(all_labels)\n",
    "label_dict, len(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0eaba04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'menu.nm',\n",
       " 'sub_total.tax_price',\n",
       " 'sub_total.etc',\n",
       " 'menu.cnt',\n",
       " 'menu.sub.nm',\n",
       " 'sub_total.subtotal_price',\n",
       " 'total.cashprice',\n",
       " 'total.changeprice',\n",
       " 'total.menuqty_cnt',\n",
       " 'menu.unitprice',\n",
       " 'total.creditcardprice',\n",
       " 'menu.sub.cnt',\n",
       " 'menu.sub.price',\n",
       " 'total.total_price',\n",
       " 'menu.price']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(set(label_dict))\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c3740b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': 0, 'menu.nm': 1, 'sub_total.tax_price': 2, 'sub_total.etc': 3, 'menu.cnt': 4, 'menu.sub.nm': 5, 'sub_total.subtotal_price': 6, 'total.cashprice': 7, 'total.changeprice': 8, 'total.menuqty_cnt': 9, 'menu.unitprice': 10, 'total.creditcardprice': 11, 'menu.sub.cnt': 12, 'menu.sub.price': 13, 'total.total_price': 14, 'menu.price': 15}\n",
      "{0: 'O', 1: 'menu.nm', 2: 'sub_total.tax_price', 3: 'sub_total.etc', 4: 'menu.cnt', 5: 'menu.sub.nm', 6: 'sub_total.subtotal_price', 7: 'total.cashprice', 8: 'total.changeprice', 9: 'total.menuqty_cnt', 10: 'menu.unitprice', 11: 'total.creditcardprice', 12: 'menu.sub.cnt', 13: 'menu.sub.price', 14: 'total.total_price', 15: 'menu.price'}\n"
     ]
    }
   ],
   "source": [
    "label2id = {label: idx for idx, label in enumerate(labels)}\n",
    "id2label = {idx: label for idx, label in enumerate(labels)}\n",
    "print(label2id)\n",
    "print(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13bacc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "def normalize_bbox(bbox, width, height):\n",
    "            return [\n",
    "                int(1000 * (bbox[0] / width)),\n",
    "                int(1000 * (bbox[1] / height)),\n",
    "                int(1000 * (bbox[2] / width)),\n",
    "                int(1000 * (bbox[3] / height)),\n",
    "            ]\n",
    "\n",
    "def create_bbox(quad_dict, width, height):\n",
    "    x_coords = [quad_dict['x1'], quad_dict['x2'], quad_dict['x3'], quad_dict['x4']]\n",
    "    y_coords = [quad_dict['y1'], quad_dict['y2'], quad_dict['y3'], quad_dict['y4']]\n",
    "\n",
    "    # Get min/max for rectangular bbox\n",
    "    x_min = min(x_coords)\n",
    "    y_min = min(y_coords)\n",
    "    x_max = max(x_coords)\n",
    "    y_max = max(y_coords)\n",
    "\n",
    "    # Ensure valid bounding box (e.g., x_min <= x_max, y_min <= y_max)\n",
    "    # This can happen if OCR is poor or annotations are malformed\n",
    "    if x_min > x_max: x_min, x_max = x_max, x_min\n",
    "    if y_min > y_max: y_min, y_max = y_max, y_min\n",
    "\n",
    "    # Normalize bounding box\n",
    "    normalized_bbox = normalize_bbox([x_min, y_min, x_max, y_max], width, height)\n",
    "\n",
    "    return normalized_bbox\n",
    "\n",
    "class CORDDataset(Dataset):\n",
    "    \"\"\"CORD dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, ground_truth, image, processor=None, max_length=512):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            annotations (List[List]): List of lists containing the word-level annotations (words, labels, boxes).\n",
    "            image_dir (string): Directory with all the document images.\n",
    "            processor (LayoutLMv2Processor): Processor to prepare the text + image.\n",
    "        \"\"\"\n",
    "        self.ground_truth = ground_truth\n",
    "        self.image = image\n",
    "        self.processor = processor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # first, take an image\n",
    "        image = self.image[idx]\n",
    "\n",
    "        width, height = image.size\n",
    "\n",
    "        sample = json.loads(self.ground_truth[idx])[\"valid_line\"]\n",
    "\n",
    "        words = []\n",
    "        boxes = []\n",
    "        word_labels = []\n",
    "\n",
    "        for val in sample:\n",
    "            for item in val[\"words\"]:\n",
    "                words.append(item[\"text\"])\n",
    "                normalized_box = create_bbox(item[\"quad\"], width, height)\n",
    "                boxes.append(normalized_box)\n",
    "                word_labels.append(val[\"category\"])\n",
    "\n",
    "        assert len(words) == len(boxes) == len(word_labels)\n",
    "        \n",
    "        word_labels = [label2id[label] for label in word_labels]\n",
    "        # use processor to prepare everything\n",
    "        encoded_inputs = self.processor(image, words, boxes=boxes, word_labels=word_labels, \n",
    "                                        padding=\"max_length\", truncation=True, \n",
    "                                        return_tensors=\"pt\")\n",
    "        \n",
    "        # remove batch dimension\n",
    "        for k,v in encoded_inputs.items():\n",
    "          encoded_inputs[k] = v.squeeze()\n",
    "      \n",
    "        return encoded_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4da95ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RobertaTokenizer'. \n",
      "The class this function is called from is 'LayoutLMv3TokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "from transformers import LayoutLMv3Processor\n",
    "\n",
    "processor = LayoutLMv3Processor.from_pretrained(\"nielsr/layoutlmv3-finetuned-cord\", apply_ocr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "392b04c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CORDDataset(ground_truth=train[\"ground_truth\"],\n",
    "                            image=train[\"image\"], \n",
    "                            processor=processor)\n",
    "validation_dataset = CORDDataset(ground_truth=validation[\"ground_truth\"],\n",
    "                            image=validation[\"image\"], \n",
    "                            processor=processor)\n",
    "test_dataset = CORDDataset(ground_truth=test[\"ground_truth\"],\n",
    "                            image=test[\"image\"], \n",
    "                            processor=processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "059475f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KeysView({'input_ids': tensor([    0,   112,  3023,   234,  8209,  4746,   710,   163,  3644,  3337,\n",
       "            6,   151,   112,  3023,   163,   428,   330, 30244,   718,   234,\n",
       "         8209, 10529,     6,   151,   112,  3023, 22124,  3609,  5113,  2141,\n",
       "        41161,  2908,     6,   151,   112,  3023,  8761, 22059, 16577,   706,\n",
       "            6,   151,   112,  3023,   234,  8209,  5847,   424, 17340,  2186,\n",
       "         1510,     6,   151,   155,  3023,  3130,  8761, 16577,   321,   112,\n",
       "         3023, 24349,  1628,  4141,  3620,     6,   151,   112,  3023,  8761,\n",
       "        16577,   504,     6,   151,   112,  3023,  8761,  5726,  1132,     6,\n",
       "          151,   112,  3023,  5847,   424,  3296,   853,   163,  3644,  5663,\n",
       "            6,   151,   132,  3023,   255, 17421, 16603,  2590,  2491,     6,\n",
       "          151,   132,  3023,  9188,  2379, 16603,  2590,  2491,     6,   151,\n",
       "          112,  3023,   255, 17421,  5477,   368,   287,   179,   843,     6,\n",
       "          151,     4,   112,  3023,   234,  8209, 16603,  2590,  1960,   428,\n",
       "         1510,     6,   151,   155,  3023,   163,   428,   330,   221,  1097,\n",
       "        21251,  1960, 40721,     6,   151,   112,  3023,  5847,   424,  1960,\n",
       "         8667,   289, 12733,  8403,     6,   151,   132,  3023,  6003, 16577,\n",
       "         3550,     6,   151,   112,  3023,  8761, 25791,   118,  2107,     6,\n",
       "          151,   112,  3023,   255, 17421,  5477,   368,   287,   179,   843,\n",
       "            6,   151,   112,  3023,  3130,  8761, 16577,   321,   112,  3023,\n",
       "         1456, 31211,   852,  3550,     6,   151,   112,  3023,  8761, 16577,\n",
       "          255, 20373,   504,     6,   151,  4052,    12, 37591,   112,     6,\n",
       "        34088,     6,   151,  1841,   727,     6, 24378, 24274,   134, 19641,\n",
       "            6, 34684,   248, 10773,   111,  1898,  2374,  5480,   112,     6,\n",
       "        40284,     6,  4697,     2,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0]), 'bbox': tensor([[  0,   0,   0,   0],\n",
       "        [268, 287, 282, 300],\n",
       "        [296, 288, 312, 300],\n",
       "        ...,\n",
       "        [  0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0]]), 'labels': tensor([-100,    4,    4,    1, -100,    1, -100,    1, -100,   15, -100, -100,\n",
       "           4,    4,    1, -100, -100,    1, -100,    1, -100,   15, -100, -100,\n",
       "           4,    4,    1, -100, -100,    1, -100,   15, -100, -100,    4,    4,\n",
       "           1,    1,    1,   15, -100, -100,    4,    4,    1, -100,    1, -100,\n",
       "           1, -100,   15, -100, -100,    4,    4,    1,    1,    1,   15,    4,\n",
       "           4,    1,    1,    1,   15, -100, -100,    4,    4,    1,    1,   15,\n",
       "        -100, -100,    4,    4,    1,    1,   15, -100, -100,    4,    4,    1,\n",
       "        -100,    1, -100,    1, -100,   15, -100, -100,    4,    4,    1, -100,\n",
       "           1, -100,   15, -100, -100,    4,    4,    1, -100,    1, -100,   15,\n",
       "        -100, -100,    4,    4,    1, -100,    1, -100,    1, -100,   15, -100,\n",
       "        -100, -100,    4,    4,    1, -100,    1, -100,    1, -100,   15, -100,\n",
       "        -100,    4,    4,    1, -100, -100,    1, -100, -100,    1,   15, -100,\n",
       "        -100,    4,    4,    1, -100,    1, -100,    1, -100,   15, -100, -100,\n",
       "           4,    4,    1,    1,   15, -100, -100,    4,    4,    1,    1, -100,\n",
       "          15, -100, -100,    4,    4,    1, -100,    1, -100,    1, -100,   15,\n",
       "        -100, -100,    4,    4,    1,    1,    1,   15,    4,    4,    1, -100,\n",
       "           1,   15, -100, -100,    4,    4,    1,    1,    1, -100,   15, -100,\n",
       "        -100,    6, -100, -100,    6, -100, -100, -100, -100,    0,    0, -100,\n",
       "        -100,    2, -100,    2, -100, -100,    3, -100,    3, -100,   14,   14,\n",
       "          14, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100]), 'pixel_values': tensor([[[-0.0667, -0.0667, -0.0824,  ...,  0.4510,  0.4588,  0.4431],\n",
       "         [-0.0667, -0.0667, -0.0667,  ...,  0.4275,  0.4588,  0.4588],\n",
       "         [-0.0588, -0.0510, -0.0588,  ...,  0.4039,  0.4353,  0.4510],\n",
       "         ...,\n",
       "         [-0.8118, -0.8039, -0.8039,  ..., -0.0196,  0.0510,  0.1294],\n",
       "         [-0.8118, -0.8039, -0.8039,  ...,  0.0118,  0.0431,  0.1608],\n",
       "         [-0.8196, -0.8118, -0.8196,  ...,  0.0431,  0.0588,  0.1373]],\n",
       "\n",
       "        [[-0.2863, -0.2863, -0.3020,  ...,  0.2706,  0.2784,  0.2549],\n",
       "         [-0.2784, -0.2863, -0.2863,  ...,  0.2471,  0.2863,  0.2784],\n",
       "         [-0.2784, -0.2706, -0.2706,  ...,  0.2235,  0.2549,  0.2784],\n",
       "         ...,\n",
       "         [-0.8588, -0.8510, -0.8510,  ..., -0.2471, -0.1765, -0.1137],\n",
       "         [-0.8588, -0.8588, -0.8588,  ..., -0.2314, -0.2000, -0.0824],\n",
       "         [-0.8745, -0.8745, -0.8745,  ..., -0.2078, -0.1922, -0.1137]],\n",
       "\n",
       "        [[-0.3255, -0.3255, -0.3490,  ...,  0.2157,  0.2235,  0.2078],\n",
       "         [-0.3176, -0.3176, -0.3255,  ...,  0.2000,  0.2314,  0.2235],\n",
       "         [-0.3098, -0.3176, -0.3176,  ...,  0.1843,  0.2078,  0.2235],\n",
       "         ...,\n",
       "         [-0.8980, -0.9137, -0.9137,  ..., -0.3412, -0.2549, -0.1922],\n",
       "         [-0.8980, -0.9059, -0.9216,  ..., -0.3176, -0.2784, -0.1608],\n",
       "         [-0.9137, -0.9216, -0.9373,  ..., -0.3098, -0.2784, -0.1922]]])})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding = train_dataset[0]\n",
    "encoding.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc89bdd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids torch.Size([512])\n",
      "attention_mask torch.Size([512])\n",
      "bbox torch.Size([512, 4])\n",
      "labels torch.Size([512])\n",
      "pixel_values torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "for k,v in encoding.items():\n",
    "  print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd4fe560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> 1 x Nasi Campur Bali 75,000 1 x Bbk Bengil Nasi 125,000 1 x MilkShake Starwb 37,000 1 x Ice Lemon Tea 24,000 1 x Nasi Ayam Dewata 70,000 3 x Free Ice Tea 0 1 x Organic Green Sa 65,000 1 x Ice Tea 18,000 1 x Ice Orange 29,000 1 x Ayam Suir Bali 85,000 2 x Tahu Goreng 36,000 2 x Tempe Goreng 36,000 1 x Tahu Telor Asin 40,000. 1 x Nasi Goreng Samb 70,000 3 x Bbk Panggang Sam 366,000 1 x Ayam Sambal Hija 92,000 2 x Hot Tea 44,000 1 x Ice Kopi 32,000 1 x Tahu Telor Asin 40,000 1 x Free Ice Tea 0 1 x Bebek Street 44,000 1 x Ice Tea Tawar 18,000 Sub-Total 1,346,000 Service 100,950 PB1 144,695 Rounding -45 Grand Total 1,591,600</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
     ]
    }
   ],
   "source": [
    "print(processor.tokenizer.decode(encoding['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3faa1abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['menu.cnt',\n",
       " 'menu.cnt',\n",
       " 'menu.nm',\n",
       " 'menu.nm',\n",
       " 'menu.nm',\n",
       " 'menu.price',\n",
       " 'menu.cnt',\n",
       " 'menu.cnt',\n",
       " 'menu.nm',\n",
       " 'menu.nm',\n",
       " 'menu.nm',\n",
       " 'menu.price',\n",
       " 'menu.cnt',\n",
       " 'menu.cnt',\n",
       " 'menu.nm',\n",
       " 'menu.nm',\n",
       " 'menu.price',\n",
       " 'menu.cnt',\n",
       " 'menu.cnt',\n",
       " 'menu.nm',\n",
       " 'menu.nm',\n",
       " 'menu.nm',\n",
       " 'menu.price',\n",
       " 'menu.cnt',\n",
       " 'menu.cnt',\n",
       " 'menu.nm',\n",
       " 'menu.nm',\n",
       " 'menu.nm',\n",
       " 'menu.price',\n",
       " 'menu.cnt',\n",
       " 'menu.cnt',\n",
       " 'menu.nm',\n",
       " 'menu.nm',\n",
       " 'menu.nm',\n",
       " 'menu.price',\n",
       " 'menu.cnt',\n",
       " 'menu.cnt',\n",
       " 'menu.nm',\n",
       " 'menu.nm',\n",
       " 'menu.nm',\n",
       " 'menu.price',\n",
       " 'menu.cnt',\n",
       " 'menu.cnt',\n",
       " 'menu.nm',\n",
       " 'menu.nm',\n",
       " 'menu.price',\n",
       " 'menu.cnt',\n",
       " 'menu.cnt',\n",
       " 'menu.nm',\n",
       " 'menu.nm',\n",
       " 'menu.price',\n",
       " 'menu.cnt',\n",
       " 'menu.cnt',\n",
       " 'menu.nm',\n",
       " 'menu.nm',\n",
       " 'menu.nm',\n",
       " 'menu.price',\n",
       " 'menu.cnt',\n",
       " 'menu.cnt',\n",
       " 'menu.nm',\n",
       " 'menu.nm',\n",
       " 'menu.price',\n",
       " 'menu.cnt',\n",
       " 'menu.cnt',\n",
       " 'menu.nm',\n",
       " 'menu.nm',\n",
       " 'menu.price',\n",
       " 'menu.cnt',\n",
       " 'menu.cnt',\n",
       " 'menu.nm',\n",
       " 'menu.nm',\n",
       " 'menu.nm',\n",
       " 'menu.price',\n",
       " 'menu.cnt',\n",
       " 'menu.cnt',\n",
       " 'menu.nm',\n",
       " 'menu.nm',\n",
       " 'menu.nm',\n",
       " 'menu.price',\n",
       " 'menu.cnt',\n",
       " 'menu.cnt',\n",
       " 'menu.nm',\n",
       " 'menu.nm',\n",
       " 'menu.nm',\n",
       " 'menu.price',\n",
       " 'menu.cnt',\n",
       " 'menu.cnt',\n",
       " 'menu.nm',\n",
       " 'menu.nm',\n",
       " 'menu.nm',\n",
       " 'menu.price',\n",
       " 'menu.cnt',\n",
       " 'menu.cnt',\n",
       " 'menu.nm',\n",
       " 'menu.nm',\n",
       " 'menu.price',\n",
       " 'menu.cnt',\n",
       " 'menu.cnt',\n",
       " 'menu.nm',\n",
       " 'menu.nm',\n",
       " 'menu.price',\n",
       " 'menu.cnt',\n",
       " 'menu.cnt',\n",
       " 'menu.nm',\n",
       " 'menu.nm',\n",
       " 'menu.nm',\n",
       " 'menu.price',\n",
       " 'menu.cnt',\n",
       " 'menu.cnt',\n",
       " 'menu.nm',\n",
       " 'menu.nm',\n",
       " 'menu.nm',\n",
       " 'menu.price',\n",
       " 'menu.cnt',\n",
       " 'menu.cnt',\n",
       " 'menu.nm',\n",
       " 'menu.nm',\n",
       " 'menu.price',\n",
       " 'menu.cnt',\n",
       " 'menu.cnt',\n",
       " 'menu.nm',\n",
       " 'menu.nm',\n",
       " 'menu.nm',\n",
       " 'menu.price',\n",
       " 'sub_total.subtotal_price',\n",
       " 'sub_total.subtotal_price',\n",
       " 'O',\n",
       " 'O',\n",
       " 'sub_total.tax_price',\n",
       " 'sub_total.tax_price',\n",
       " 'sub_total.etc',\n",
       " 'sub_total.etc',\n",
       " 'total.total_price',\n",
       " 'total.total_price',\n",
       " 'total.total_price']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[id2label[label] for label in encoding['labels'].tolist() if label != -100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89a1bfec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> -100\n",
      " 1 4\n",
      " x 4\n",
      " N 1\n",
      "asi -100\n",
      " Camp 1\n",
      "ur -100\n",
      " B 1\n",
      "ali -100\n",
      " 75 15\n",
      ", -100\n",
      "000 -100\n",
      " 1 4\n",
      " x 4\n",
      " B 1\n",
      "b -100\n",
      "k -100\n",
      " Beng 1\n",
      "il -100\n",
      " N 1\n",
      "asi -100\n",
      " 125 15\n",
      ", -100\n",
      "000 -100\n",
      " 1 4\n",
      " x 4\n",
      " Milk 1\n",
      "Sh -100\n",
      "ake -100\n",
      " Star 1\n"
     ]
    }
   ],
   "source": [
    "for id, label in zip(encoding['input_ids'][:30], encoding['labels'][:30]):\n",
    "  print(processor.tokenizer.decode([id]), label.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b36cf237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x15109beefe0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x15109befbb0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x15109befb20>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE=2\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "train_dataloader, validation_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb46ab1",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd58f47f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LayoutLMv3ForTokenClassification were not initialized from the model checkpoint at nielsr/layoutlmv3-finetuned-cord and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.bias: found shape torch.Size([61]) in the checkpoint and torch.Size([16]) in the model instantiated\n",
      "- classifier.out_proj.weight: found shape torch.Size([61, 768]) in the checkpoint and torch.Size([16, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained('nielsr/layoutlmv3-finetuned-cord', num_labels=len(labels), ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ccbd80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92a850d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 512\n",
    "image_channels = 3\n",
    "image_height = 224\n",
    "image_width = 224\n",
    "\n",
    "# Create dummy input tensors with the CORRECT dtypes and move them to the device\n",
    "# input_ids, attention_mask, bbox, and token_type_ids should be torch.long\n",
    "# pixel_values should be torch.float\n",
    "\n",
    "dummy_input_ids = torch.randint(0, model.config.vocab_size, (BATCH_SIZE, sequence_length), dtype=torch.long, device=device)\n",
    "dummy_attention_mask = torch.ones((BATCH_SIZE, sequence_length), dtype=torch.long, device=device)\n",
    "dummy_bbox = torch.randint(0, 1000, (BATCH_SIZE, sequence_length, 4), dtype=torch.long, device=device)\n",
    "dummy_pixel_values = torch.randn((BATCH_SIZE, image_channels, image_height, image_width), dtype=torch.float, device=device)\n",
    "\n",
    "# Crucially, LayoutLMv3 models often expect `token_type_ids`.\n",
    "# Even if your specific forward pass doesn't show it explicitly in your snippet,\n",
    "# the traceback shows `token_type_ids=token_type_ids` deeper in the call stack.\n",
    "# It's safest to include it.\n",
    "dummy_labels = torch.zeros((BATCH_SIZE, sequence_length), dtype=torch.long, device=device)\n",
    "\n",
    "\n",
    "# Provide these dummy tensors to torchinfo using `input_data`\n",
    "# This ensures that torchinfo passes inputs with the correct names and dtypes\n",
    "input_data = {\n",
    "    \"input_ids\": dummy_input_ids,\n",
    "    \"attention_mask\": dummy_attention_mask,\n",
    "    \"bbox\": dummy_bbox,\n",
    "    \"labels\": dummy_labels,\n",
    "    \"pixel_values\": dummy_pixel_values, # Add this\n",
    "    # If your model expects 'labels' for `forward` during summary, you'd add:\n",
    "    # \"labels\": torch.randint(0, num_classes, (BATCH_SIZE,), dtype=torch.long, device=device)\n",
    "    # or for token classification:\n",
    "    # \"labels\": torch.randint(0, num_labels, (BATCH_SIZE, sequence_length), dtype=torch.long, device=device)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa2bb04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python_projects\\Kaggle_Gym\\.venv\\lib\\site-packages\\transformers\\modeling_utils.py:1731: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "======================================================================================================================================================\n",
       "Layer (type (var_name))                                                Input Shape          Output Shape         Param #              Trainable\n",
       "======================================================================================================================================================\n",
       "LayoutLMv3ForTokenClassification (LayoutLMv3ForTokenClassification)    --                   [2, 512, 16]         --                   True\n",
       "├─LayoutLMv3Model (layoutlmv3)                                         [2, 512]             [2, 709, 768]        152,064              True\n",
       "│    └─LayoutLMv3TextEmbeddings (embeddings)                           --                   [2, 512, 768]        --                   True\n",
       "│    │    └─Embedding (word_embeddings)                                [2, 512]             [2, 512, 768]        38,603,520           True\n",
       "│    │    └─Embedding (token_type_embeddings)                          [2, 512]             [2, 512, 768]        768                  True\n",
       "│    │    └─Embedding (position_embeddings)                            [2, 512]             [2, 512, 768]        394,752              True\n",
       "│    │    └─Embedding (x_position_embeddings)                          [2, 512]             [2, 512, 128]        131,072              True\n",
       "│    │    └─Embedding (y_position_embeddings)                          [2, 512]             [2, 512, 128]        131,072              True\n",
       "│    │    └─Embedding (x_position_embeddings)                          [2, 512]             [2, 512, 128]        (recursive)          True\n",
       "│    │    └─Embedding (y_position_embeddings)                          [2, 512]             [2, 512, 128]        (recursive)          True\n",
       "│    │    └─Embedding (h_position_embeddings)                          [2, 512]             [2, 512, 128]        131,072              True\n",
       "│    │    └─Embedding (w_position_embeddings)                          [2, 512]             [2, 512, 128]        131,072              True\n",
       "│    │    └─LayerNorm (LayerNorm)                                      [2, 512, 768]        [2, 512, 768]        1,536                True\n",
       "│    │    └─Dropout (dropout)                                          [2, 512, 768]        [2, 512, 768]        --                   --\n",
       "│    └─LayoutLMv3PatchEmbeddings (patch_embed)                         [2, 3, 224, 224]     [2, 196, 768]        --                   True\n",
       "│    │    └─Conv2d (proj)                                              [2, 3, 224, 224]     [2, 768, 14, 14]     590,592              True\n",
       "│    └─Dropout (pos_drop)                                              [2, 197, 768]        [2, 197, 768]        --                   --\n",
       "│    └─LayerNorm (norm)                                                [2, 197, 768]        [2, 197, 768]        1,536                True\n",
       "│    └─LayerNorm (LayerNorm)                                           [2, 709, 768]        [2, 709, 768]        1,536                True\n",
       "│    └─Dropout (dropout)                                               [2, 709, 768]        [2, 709, 768]        --                   --\n",
       "│    └─LayoutLMv3Encoder (encoder)                                     [2, 709, 768]        [2, 709, 768]        1,920                True\n",
       "│    │    └─ModuleList (layer)                                         --                   --                   --                   True\n",
       "│    │    │    └─LayoutLMv3Layer (0)                                   [2, 709, 768]        [2, 709, 768]        7,087,872            True\n",
       "│    │    │    └─LayoutLMv3Layer (1)                                   [2, 709, 768]        [2, 709, 768]        7,087,872            True\n",
       "│    │    │    └─LayoutLMv3Layer (2)                                   [2, 709, 768]        [2, 709, 768]        7,087,872            True\n",
       "│    │    │    └─LayoutLMv3Layer (3)                                   [2, 709, 768]        [2, 709, 768]        7,087,872            True\n",
       "│    │    │    └─LayoutLMv3Layer (4)                                   [2, 709, 768]        [2, 709, 768]        7,087,872            True\n",
       "│    │    │    └─LayoutLMv3Layer (5)                                   [2, 709, 768]        [2, 709, 768]        7,087,872            True\n",
       "│    │    │    └─LayoutLMv3Layer (6)                                   [2, 709, 768]        [2, 709, 768]        7,087,872            True\n",
       "│    │    │    └─LayoutLMv3Layer (7)                                   [2, 709, 768]        [2, 709, 768]        7,087,872            True\n",
       "│    │    │    └─LayoutLMv3Layer (8)                                   [2, 709, 768]        [2, 709, 768]        7,087,872            True\n",
       "│    │    │    └─LayoutLMv3Layer (9)                                   [2, 709, 768]        [2, 709, 768]        7,087,872            True\n",
       "│    │    │    └─LayoutLMv3Layer (10)                                  [2, 709, 768]        [2, 709, 768]        7,087,872            True\n",
       "│    │    │    └─LayoutLMv3Layer (11)                                  [2, 709, 768]        [2, 709, 768]        7,087,872            True\n",
       "├─Dropout (dropout)                                                    [2, 512, 768]        [2, 512, 768]        --                   --\n",
       "├─LayoutLMv3ClassificationHead (classifier)                            [2, 512, 768]        [2, 512, 16]         --                   True\n",
       "│    └─Dropout (dropout)                                               [2, 512, 768]        [2, 512, 768]        --                   --\n",
       "│    └─Linear (dense)                                                  [2, 512, 768]        [2, 512, 768]        590,592              True\n",
       "│    └─Dropout (dropout)                                               [2, 512, 768]        [2, 512, 768]        --                   --\n",
       "│    └─Linear (out_proj)                                               [2, 512, 768]        [2, 512, 16]         12,304               True\n",
       "======================================================================================================================================================\n",
       "Total params: 125,929,872\n",
       "Trainable params: 125,929,872\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 482.41\n",
       "======================================================================================================================================================\n",
       "Input size (MB): 1.26\n",
       "Forward/backward pass size (MB): 1201.43\n",
       "Params size (MB): 503.10\n",
       "Estimated Total Size (MB): 1705.80\n",
       "======================================================================================================================================================"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "# input_ids torch.Size([512])\n",
    "# attention_mask torch.Size([512])\n",
    "# bbox torch.Size([512, 4])\n",
    "# labels torch.Size([512])\n",
    "# pixel_values torch.Size([3, 224, 224])\n",
    "\n",
    "\n",
    "summary(model, input_data=input_data, depth=4, col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"], col_width=20, row_settings=[\"var_names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a7129c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoModel\n",
    "model = AutoModel.from_pretrained(\"microsoft/layoutlmv3-base\", torch_dtype=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f5deaaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "================================================================================\n",
       "Layer (type:depth-idx)                                  Param #\n",
       "================================================================================\n",
       "LayoutLMv3Model                                         152,064\n",
       "├─LayoutLMv3TextEmbeddings: 1-1                         --\n",
       "│    └─Embedding: 2-1                                   38,603,520\n",
       "│    └─Embedding: 2-2                                   768\n",
       "│    └─LayerNorm: 2-3                                   1,536\n",
       "│    └─Dropout: 2-4                                     --\n",
       "│    └─Embedding: 2-5                                   394,752\n",
       "│    └─Embedding: 2-6                                   131,072\n",
       "│    └─Embedding: 2-7                                   131,072\n",
       "│    └─Embedding: 2-8                                   131,072\n",
       "│    └─Embedding: 2-9                                   131,072\n",
       "├─LayoutLMv3PatchEmbeddings: 1-2                        --\n",
       "│    └─Conv2d: 2-10                                     590,592\n",
       "├─Dropout: 1-3                                          --\n",
       "├─LayerNorm: 1-4                                        1,536\n",
       "├─Dropout: 1-5                                          --\n",
       "├─LayerNorm: 1-6                                        1,536\n",
       "├─LayoutLMv3Encoder: 1-7                                --\n",
       "│    └─ModuleList: 2-11                                 --\n",
       "│    │    └─LayoutLMv3Layer: 3-1                        7,087,872\n",
       "│    │    └─LayoutLMv3Layer: 3-2                        7,087,872\n",
       "│    │    └─LayoutLMv3Layer: 3-3                        7,087,872\n",
       "│    │    └─LayoutLMv3Layer: 3-4                        7,087,872\n",
       "│    │    └─LayoutLMv3Layer: 3-5                        7,087,872\n",
       "│    │    └─LayoutLMv3Layer: 3-6                        7,087,872\n",
       "│    │    └─LayoutLMv3Layer: 3-7                        7,087,872\n",
       "│    │    └─LayoutLMv3Layer: 3-8                        7,087,872\n",
       "│    │    └─LayoutLMv3Layer: 3-9                        7,087,872\n",
       "│    │    └─LayoutLMv3Layer: 3-10                       7,087,872\n",
       "│    │    └─LayoutLMv3Layer: 3-11                       7,087,872\n",
       "│    │    └─LayoutLMv3Layer: 3-12                       7,087,872\n",
       "│    └─Linear: 2-12                                     384\n",
       "│    └─Linear: 2-13                                     768\n",
       "│    └─Linear: 2-14                                     768\n",
       "================================================================================\n",
       "Total params: 125,326,976\n",
       "Trainable params: 125,326,976\n",
       "Non-trainable params: 0\n",
       "================================================================================"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eef4db1",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "19e5ba6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> 901016 -TICKET CP 2 60.000 60.000 TOTAL DISC $ -60.000 TAX 5.455 Subtotal 60.000 TOTAL 60.000 (Qty 2.00 EDC CIMB NIAGA No: xx7730 60.000</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding = test_dataset[0]\n",
    "processor.tokenizer.decode(encoding['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5ae0450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'menu.nm', 'menu.nm', 'menu.cnt', 'menu.price', 'O', 'O', 'O', 'O', 'O', 'sub_total.tax_price', 'sub_total.tax_price', 'sub_total.subtotal_price', 'sub_total.subtotal_price', 'total.total_price', 'total.total_price', 'total.menuqty_cnt', 'total.menuqty_cnt', 'total.creditcardprice', 'total.creditcardprice', 'total.creditcardprice', 'total.creditcardprice', 'total.creditcardprice', 'total.creditcardprice']\n"
     ]
    }
   ],
   "source": [
    "ground_truth_labels = [id2label[label] for label in encoding['labels'].squeeze().tolist() if label != -100]\n",
    "print(ground_truth_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
